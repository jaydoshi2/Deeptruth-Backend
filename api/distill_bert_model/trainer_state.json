{
  "best_global_step": 2366,
  "best_metric": 0.37970879673957825,
  "best_model_checkpoint": "./distil_results/run-0/checkpoint-2366",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 5915,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.042265426880811495,
      "grad_norm": 1.6131688356399536,
      "learning_rate": 2.181881483785051e-05,
      "loss": 0.6744,
      "step": 50
    },
    {
      "epoch": 0.08453085376162299,
      "grad_norm": 3.752645492553711,
      "learning_rate": 2.163280618620643e-05,
      "loss": 0.5836,
      "step": 100
    },
    {
      "epoch": 0.12679628064243448,
      "grad_norm": 2.6986958980560303,
      "learning_rate": 2.1446797534562352e-05,
      "loss": 0.6049,
      "step": 150
    },
    {
      "epoch": 0.16906170752324598,
      "grad_norm": 4.270266056060791,
      "learning_rate": 2.1260788882918273e-05,
      "loss": 0.5787,
      "step": 200
    },
    {
      "epoch": 0.21132713440405748,
      "grad_norm": 2.9483642578125,
      "learning_rate": 2.1074780231274193e-05,
      "loss": 0.5869,
      "step": 250
    },
    {
      "epoch": 0.25359256128486896,
      "grad_norm": 3.9547152519226074,
      "learning_rate": 2.0888771579630114e-05,
      "loss": 0.5456,
      "step": 300
    },
    {
      "epoch": 0.2958579881656805,
      "grad_norm": 2.2173333168029785,
      "learning_rate": 2.0702762927986035e-05,
      "loss": 0.5415,
      "step": 350
    },
    {
      "epoch": 0.33812341504649196,
      "grad_norm": 2.464552402496338,
      "learning_rate": 2.0516754276341955e-05,
      "loss": 0.5246,
      "step": 400
    },
    {
      "epoch": 0.3803888419273035,
      "grad_norm": 4.744137287139893,
      "learning_rate": 2.0330745624697876e-05,
      "loss": 0.5413,
      "step": 450
    },
    {
      "epoch": 0.42265426880811496,
      "grad_norm": 4.21375846862793,
      "learning_rate": 2.0144736973053797e-05,
      "loss": 0.5142,
      "step": 500
    },
    {
      "epoch": 0.46491969568892644,
      "grad_norm": 4.735536098480225,
      "learning_rate": 1.9958728321409717e-05,
      "loss": 0.5123,
      "step": 550
    },
    {
      "epoch": 0.5071851225697379,
      "grad_norm": 3.6354358196258545,
      "learning_rate": 1.9772719669765638e-05,
      "loss": 0.5029,
      "step": 600
    },
    {
      "epoch": 0.5494505494505495,
      "grad_norm": 2.521092414855957,
      "learning_rate": 1.958671101812156e-05,
      "loss": 0.5127,
      "step": 650
    },
    {
      "epoch": 0.591715976331361,
      "grad_norm": 3.2152984142303467,
      "learning_rate": 1.940070236647748e-05,
      "loss": 0.5169,
      "step": 700
    },
    {
      "epoch": 0.6339814032121724,
      "grad_norm": 3.6254546642303467,
      "learning_rate": 1.92146937148334e-05,
      "loss": 0.4818,
      "step": 750
    },
    {
      "epoch": 0.6762468300929839,
      "grad_norm": 4.349707126617432,
      "learning_rate": 1.902868506318932e-05,
      "loss": 0.5104,
      "step": 800
    },
    {
      "epoch": 0.7185122569737954,
      "grad_norm": 2.181246519088745,
      "learning_rate": 1.884267641154524e-05,
      "loss": 0.4777,
      "step": 850
    },
    {
      "epoch": 0.760777683854607,
      "grad_norm": 2.7801718711853027,
      "learning_rate": 1.8656667759901162e-05,
      "loss": 0.5021,
      "step": 900
    },
    {
      "epoch": 0.8030431107354185,
      "grad_norm": 3.722513437271118,
      "learning_rate": 1.8470659108257082e-05,
      "loss": 0.4794,
      "step": 950
    },
    {
      "epoch": 0.8453085376162299,
      "grad_norm": 4.658679962158203,
      "learning_rate": 1.8284650456613003e-05,
      "loss": 0.4693,
      "step": 1000
    },
    {
      "epoch": 0.8875739644970414,
      "grad_norm": 3.2568531036376953,
      "learning_rate": 1.8098641804968924e-05,
      "loss": 0.4724,
      "step": 1050
    },
    {
      "epoch": 0.9298393913778529,
      "grad_norm": 8.039826393127441,
      "learning_rate": 1.7912633153324844e-05,
      "loss": 0.4909,
      "step": 1100
    },
    {
      "epoch": 0.9721048182586645,
      "grad_norm": 4.776088714599609,
      "learning_rate": 1.7726624501680765e-05,
      "loss": 0.4537,
      "step": 1150
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7839923873969127,
      "eval_f1": 0.7837079214828181,
      "eval_loss": 0.44755983352661133,
      "eval_runtime": 34.0974,
      "eval_samples_per_second": 277.382,
      "eval_steps_per_second": 34.695,
      "step": 1183
    },
    {
      "epoch": 1.0143702451394758,
      "grad_norm": 3.6944830417633057,
      "learning_rate": 1.7540615850036686e-05,
      "loss": 0.4271,
      "step": 1200
    },
    {
      "epoch": 1.0566356720202874,
      "grad_norm": 4.165809154510498,
      "learning_rate": 1.7354607198392606e-05,
      "loss": 0.4019,
      "step": 1250
    },
    {
      "epoch": 1.098901098901099,
      "grad_norm": 3.1047959327697754,
      "learning_rate": 1.7168598546748527e-05,
      "loss": 0.4037,
      "step": 1300
    },
    {
      "epoch": 1.1411665257819104,
      "grad_norm": 5.827052593231201,
      "learning_rate": 1.6982589895104448e-05,
      "loss": 0.4083,
      "step": 1350
    },
    {
      "epoch": 1.183431952662722,
      "grad_norm": 4.953545570373535,
      "learning_rate": 1.679658124346037e-05,
      "loss": 0.3675,
      "step": 1400
    },
    {
      "epoch": 1.2256973795435333,
      "grad_norm": 3.4510159492492676,
      "learning_rate": 1.661057259181629e-05,
      "loss": 0.4034,
      "step": 1450
    },
    {
      "epoch": 1.267962806424345,
      "grad_norm": 6.2848381996154785,
      "learning_rate": 1.642456394017221e-05,
      "loss": 0.3807,
      "step": 1500
    },
    {
      "epoch": 1.3102282333051565,
      "grad_norm": 5.499932765960693,
      "learning_rate": 1.623855528852813e-05,
      "loss": 0.3534,
      "step": 1550
    },
    {
      "epoch": 1.3524936601859678,
      "grad_norm": 8.225550651550293,
      "learning_rate": 1.605254663688405e-05,
      "loss": 0.3647,
      "step": 1600
    },
    {
      "epoch": 1.3947590870667794,
      "grad_norm": 7.49005126953125,
      "learning_rate": 1.5866537985239972e-05,
      "loss": 0.3522,
      "step": 1650
    },
    {
      "epoch": 1.4370245139475908,
      "grad_norm": 5.185392379760742,
      "learning_rate": 1.5680529333595892e-05,
      "loss": 0.3621,
      "step": 1700
    },
    {
      "epoch": 1.4792899408284024,
      "grad_norm": 5.537572860717773,
      "learning_rate": 1.5494520681951813e-05,
      "loss": 0.3606,
      "step": 1750
    },
    {
      "epoch": 1.521555367709214,
      "grad_norm": 4.1982197761535645,
      "learning_rate": 1.5308512030307734e-05,
      "loss": 0.3816,
      "step": 1800
    },
    {
      "epoch": 1.5638207945900253,
      "grad_norm": 2.188809633255005,
      "learning_rate": 1.5122503378663654e-05,
      "loss": 0.3544,
      "step": 1850
    },
    {
      "epoch": 1.606086221470837,
      "grad_norm": 9.066466331481934,
      "learning_rate": 1.4936494727019573e-05,
      "loss": 0.3467,
      "step": 1900
    },
    {
      "epoch": 1.6483516483516483,
      "grad_norm": 6.6143951416015625,
      "learning_rate": 1.4750486075375494e-05,
      "loss": 0.3563,
      "step": 1950
    },
    {
      "epoch": 1.6906170752324599,
      "grad_norm": 4.894742488861084,
      "learning_rate": 1.4564477423731415e-05,
      "loss": 0.349,
      "step": 2000
    },
    {
      "epoch": 1.7328825021132714,
      "grad_norm": 3.2086164951324463,
      "learning_rate": 1.4378468772087335e-05,
      "loss": 0.3461,
      "step": 2050
    },
    {
      "epoch": 1.7751479289940828,
      "grad_norm": 5.112067222595215,
      "learning_rate": 1.4192460120443256e-05,
      "loss": 0.3561,
      "step": 2100
    },
    {
      "epoch": 1.8174133558748944,
      "grad_norm": 7.434057235717773,
      "learning_rate": 1.4006451468799177e-05,
      "loss": 0.3323,
      "step": 2150
    },
    {
      "epoch": 1.8596787827557058,
      "grad_norm": 7.559322357177734,
      "learning_rate": 1.3820442817155097e-05,
      "loss": 0.3344,
      "step": 2200
    },
    {
      "epoch": 1.9019442096365173,
      "grad_norm": 5.67589807510376,
      "learning_rate": 1.3634434165511018e-05,
      "loss": 0.3202,
      "step": 2250
    },
    {
      "epoch": 1.944209636517329,
      "grad_norm": 6.001195430755615,
      "learning_rate": 1.3448425513866939e-05,
      "loss": 0.3319,
      "step": 2300
    },
    {
      "epoch": 1.9864750633981403,
      "grad_norm": 3.3669610023498535,
      "learning_rate": 1.326241686222286e-05,
      "loss": 0.334,
      "step": 2350
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8345316134489321,
      "eval_f1": 0.8344553513765488,
      "eval_loss": 0.37970879673957825,
      "eval_runtime": 34.0414,
      "eval_samples_per_second": 277.839,
      "eval_steps_per_second": 34.752,
      "step": 2366
    },
    {
      "epoch": 2.0287404902789516,
      "grad_norm": 6.775138854980469,
      "learning_rate": 1.307640821057878e-05,
      "loss": 0.2823,
      "step": 2400
    },
    {
      "epoch": 2.0710059171597632,
      "grad_norm": 7.591593265533447,
      "learning_rate": 1.28903995589347e-05,
      "loss": 0.2495,
      "step": 2450
    },
    {
      "epoch": 2.113271344040575,
      "grad_norm": 9.338213920593262,
      "learning_rate": 1.2704390907290621e-05,
      "loss": 0.2523,
      "step": 2500
    },
    {
      "epoch": 2.1555367709213864,
      "grad_norm": 10.91507339477539,
      "learning_rate": 1.2518382255646542e-05,
      "loss": 0.2127,
      "step": 2550
    },
    {
      "epoch": 2.197802197802198,
      "grad_norm": 7.183594226837158,
      "learning_rate": 1.2332373604002463e-05,
      "loss": 0.2376,
      "step": 2600
    },
    {
      "epoch": 2.240067624683009,
      "grad_norm": 6.370297431945801,
      "learning_rate": 1.2146364952358383e-05,
      "loss": 0.2252,
      "step": 2650
    },
    {
      "epoch": 2.2823330515638207,
      "grad_norm": 6.708451271057129,
      "learning_rate": 1.1960356300714304e-05,
      "loss": 0.2286,
      "step": 2700
    },
    {
      "epoch": 2.3245984784446323,
      "grad_norm": 6.3853983879089355,
      "learning_rate": 1.1774347649070225e-05,
      "loss": 0.2406,
      "step": 2750
    },
    {
      "epoch": 2.366863905325444,
      "grad_norm": 6.731246471405029,
      "learning_rate": 1.1588338997426145e-05,
      "loss": 0.2269,
      "step": 2800
    },
    {
      "epoch": 2.4091293322062555,
      "grad_norm": 6.130976676940918,
      "learning_rate": 1.1402330345782066e-05,
      "loss": 0.229,
      "step": 2850
    },
    {
      "epoch": 2.4513947590870666,
      "grad_norm": 6.436036109924316,
      "learning_rate": 1.1216321694137987e-05,
      "loss": 0.2169,
      "step": 2900
    },
    {
      "epoch": 2.493660185967878,
      "grad_norm": 10.083009719848633,
      "learning_rate": 1.1030313042493907e-05,
      "loss": 0.2395,
      "step": 2950
    },
    {
      "epoch": 2.53592561284869,
      "grad_norm": 17.10666847229004,
      "learning_rate": 1.0844304390849828e-05,
      "loss": 0.2005,
      "step": 3000
    },
    {
      "epoch": 2.5781910397295014,
      "grad_norm": 14.360136985778809,
      "learning_rate": 1.0658295739205749e-05,
      "loss": 0.2352,
      "step": 3050
    },
    {
      "epoch": 2.620456466610313,
      "grad_norm": 3.8744428157806396,
      "learning_rate": 1.047228708756167e-05,
      "loss": 0.2163,
      "step": 3100
    },
    {
      "epoch": 2.662721893491124,
      "grad_norm": 6.881134986877441,
      "learning_rate": 1.028627843591759e-05,
      "loss": 0.216,
      "step": 3150
    },
    {
      "epoch": 2.7049873203719357,
      "grad_norm": 6.621644020080566,
      "learning_rate": 1.010026978427351e-05,
      "loss": 0.221,
      "step": 3200
    },
    {
      "epoch": 2.7472527472527473,
      "grad_norm": 11.150359153747559,
      "learning_rate": 9.914261132629431e-06,
      "loss": 0.2238,
      "step": 3250
    },
    {
      "epoch": 2.789518174133559,
      "grad_norm": 6.884805202484131,
      "learning_rate": 9.728252480985352e-06,
      "loss": 0.2238,
      "step": 3300
    },
    {
      "epoch": 2.8317836010143704,
      "grad_norm": 8.978039741516113,
      "learning_rate": 9.542243829341272e-06,
      "loss": 0.205,
      "step": 3350
    },
    {
      "epoch": 2.8740490278951816,
      "grad_norm": 8.36902141571045,
      "learning_rate": 9.356235177697193e-06,
      "loss": 0.2215,
      "step": 3400
    },
    {
      "epoch": 2.916314454775993,
      "grad_norm": 11.619752883911133,
      "learning_rate": 9.170226526053114e-06,
      "loss": 0.259,
      "step": 3450
    },
    {
      "epoch": 2.9585798816568047,
      "grad_norm": 14.955972671508789,
      "learning_rate": 8.984217874409033e-06,
      "loss": 0.1987,
      "step": 3500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8434129837174879,
      "eval_f1": 0.8425380903407441,
      "eval_loss": 0.41658005118370056,
      "eval_runtime": 34.3809,
      "eval_samples_per_second": 275.095,
      "eval_steps_per_second": 34.409,
      "step": 3549
    },
    {
      "epoch": 3.0008453085376163,
      "grad_norm": 6.378751754760742,
      "learning_rate": 8.798209222764953e-06,
      "loss": 0.2141,
      "step": 3550
    },
    {
      "epoch": 3.043110735418428,
      "grad_norm": 7.245075225830078,
      "learning_rate": 8.612200571120874e-06,
      "loss": 0.1341,
      "step": 3600
    },
    {
      "epoch": 3.085376162299239,
      "grad_norm": 4.117544651031494,
      "learning_rate": 8.426191919476795e-06,
      "loss": 0.124,
      "step": 3650
    },
    {
      "epoch": 3.1276415891800506,
      "grad_norm": 8.555564880371094,
      "learning_rate": 8.240183267832715e-06,
      "loss": 0.1419,
      "step": 3700
    },
    {
      "epoch": 3.1699070160608622,
      "grad_norm": 6.950589656829834,
      "learning_rate": 8.054174616188636e-06,
      "loss": 0.1323,
      "step": 3750
    },
    {
      "epoch": 3.212172442941674,
      "grad_norm": 3.9665424823760986,
      "learning_rate": 7.868165964544557e-06,
      "loss": 0.153,
      "step": 3800
    },
    {
      "epoch": 3.2544378698224854,
      "grad_norm": 10.486099243164062,
      "learning_rate": 7.682157312900479e-06,
      "loss": 0.1241,
      "step": 3850
    },
    {
      "epoch": 3.2967032967032965,
      "grad_norm": 8.897225379943848,
      "learning_rate": 7.496148661256399e-06,
      "loss": 0.1827,
      "step": 3900
    },
    {
      "epoch": 3.338968723584108,
      "grad_norm": 7.722984790802002,
      "learning_rate": 7.3101400096123196e-06,
      "loss": 0.1527,
      "step": 3950
    },
    {
      "epoch": 3.3812341504649197,
      "grad_norm": 1.8605605363845825,
      "learning_rate": 7.12413135796824e-06,
      "loss": 0.125,
      "step": 4000
    },
    {
      "epoch": 3.4234995773457313,
      "grad_norm": 15.26416301727295,
      "learning_rate": 6.938122706324161e-06,
      "loss": 0.1406,
      "step": 4050
    },
    {
      "epoch": 3.465765004226543,
      "grad_norm": 3.8782246112823486,
      "learning_rate": 6.752114054680081e-06,
      "loss": 0.1326,
      "step": 4100
    },
    {
      "epoch": 3.508030431107354,
      "grad_norm": 7.012698173522949,
      "learning_rate": 6.566105403036001e-06,
      "loss": 0.1375,
      "step": 4150
    },
    {
      "epoch": 3.5502958579881656,
      "grad_norm": 19.81850242614746,
      "learning_rate": 6.380096751391922e-06,
      "loss": 0.1268,
      "step": 4200
    },
    {
      "epoch": 3.592561284868977,
      "grad_norm": 18.857587814331055,
      "learning_rate": 6.194088099747843e-06,
      "loss": 0.1543,
      "step": 4250
    },
    {
      "epoch": 3.6348267117497888,
      "grad_norm": 1.808325171470642,
      "learning_rate": 6.008079448103763e-06,
      "loss": 0.1223,
      "step": 4300
    },
    {
      "epoch": 3.6770921386306004,
      "grad_norm": 10.54426097869873,
      "learning_rate": 5.822070796459684e-06,
      "loss": 0.1563,
      "step": 4350
    },
    {
      "epoch": 3.7193575655114115,
      "grad_norm": 4.803995609283447,
      "learning_rate": 5.636062144815605e-06,
      "loss": 0.1352,
      "step": 4400
    },
    {
      "epoch": 3.761622992392223,
      "grad_norm": 12.43560791015625,
      "learning_rate": 5.450053493171525e-06,
      "loss": 0.1364,
      "step": 4450
    },
    {
      "epoch": 3.8038884192730347,
      "grad_norm": 13.812141418457031,
      "learning_rate": 5.264044841527447e-06,
      "loss": 0.1411,
      "step": 4500
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 7.50599479675293,
      "learning_rate": 5.0780361898833675e-06,
      "loss": 0.1183,
      "step": 4550
    },
    {
      "epoch": 3.888419273034658,
      "grad_norm": 11.040383338928223,
      "learning_rate": 4.892027538239287e-06,
      "loss": 0.1588,
      "step": 4600
    },
    {
      "epoch": 3.930684699915469,
      "grad_norm": 8.441844940185547,
      "learning_rate": 4.706018886595208e-06,
      "loss": 0.1191,
      "step": 4650
    },
    {
      "epoch": 3.9729501267962806,
      "grad_norm": 10.614059448242188,
      "learning_rate": 4.520010234951129e-06,
      "loss": 0.1259,
      "step": 4700
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8651934869951364,
      "eval_f1": 0.864897090177785,
      "eval_loss": 0.4552273154258728,
      "eval_runtime": 34.1863,
      "eval_samples_per_second": 276.661,
      "eval_steps_per_second": 34.605,
      "step": 4732
    },
    {
      "epoch": 4.015215553677092,
      "grad_norm": 8.81058406829834,
      "learning_rate": 4.334001583307049e-06,
      "loss": 0.134,
      "step": 4750
    },
    {
      "epoch": 4.057480980557903,
      "grad_norm": 10.34593677520752,
      "learning_rate": 4.14799293166297e-06,
      "loss": 0.099,
      "step": 4800
    },
    {
      "epoch": 4.099746407438715,
      "grad_norm": 2.8157572746276855,
      "learning_rate": 3.961984280018891e-06,
      "loss": 0.0931,
      "step": 4850
    },
    {
      "epoch": 4.1420118343195265,
      "grad_norm": 6.378989219665527,
      "learning_rate": 3.775975628374811e-06,
      "loss": 0.0808,
      "step": 4900
    },
    {
      "epoch": 4.1842772612003385,
      "grad_norm": 2.855377674102783,
      "learning_rate": 3.589966976730732e-06,
      "loss": 0.0916,
      "step": 4950
    },
    {
      "epoch": 4.22654268808115,
      "grad_norm": 12.774465560913086,
      "learning_rate": 3.4039583250866526e-06,
      "loss": 0.0976,
      "step": 5000
    },
    {
      "epoch": 4.268808114961961,
      "grad_norm": 8.842854499816895,
      "learning_rate": 3.2179496734425733e-06,
      "loss": 0.0979,
      "step": 5050
    },
    {
      "epoch": 4.311073541842773,
      "grad_norm": 7.688976287841797,
      "learning_rate": 3.031941021798494e-06,
      "loss": 0.0987,
      "step": 5100
    },
    {
      "epoch": 4.353338968723584,
      "grad_norm": 19.243938446044922,
      "learning_rate": 2.8459323701544146e-06,
      "loss": 0.0915,
      "step": 5150
    },
    {
      "epoch": 4.395604395604396,
      "grad_norm": 8.848146438598633,
      "learning_rate": 2.6599237185103352e-06,
      "loss": 0.0971,
      "step": 5200
    },
    {
      "epoch": 4.437869822485207,
      "grad_norm": 3.5025506019592285,
      "learning_rate": 2.473915066866256e-06,
      "loss": 0.0912,
      "step": 5250
    },
    {
      "epoch": 4.480135249366018,
      "grad_norm": 4.7308783531188965,
      "learning_rate": 2.287906415222176e-06,
      "loss": 0.0757,
      "step": 5300
    },
    {
      "epoch": 4.52240067624683,
      "grad_norm": 13.047369003295898,
      "learning_rate": 2.101897763578097e-06,
      "loss": 0.0803,
      "step": 5350
    },
    {
      "epoch": 4.564666103127641,
      "grad_norm": 12.762035369873047,
      "learning_rate": 1.9158891119340175e-06,
      "loss": 0.0843,
      "step": 5400
    },
    {
      "epoch": 4.6069315300084535,
      "grad_norm": 19.062759399414062,
      "learning_rate": 1.7298804602899381e-06,
      "loss": 0.0763,
      "step": 5450
    },
    {
      "epoch": 4.649196956889265,
      "grad_norm": 12.013127326965332,
      "learning_rate": 1.5438718086458588e-06,
      "loss": 0.068,
      "step": 5500
    },
    {
      "epoch": 4.691462383770076,
      "grad_norm": 7.684622764587402,
      "learning_rate": 1.3578631570017794e-06,
      "loss": 0.0839,
      "step": 5550
    },
    {
      "epoch": 4.733727810650888,
      "grad_norm": 17.165287017822266,
      "learning_rate": 1.1718545053577e-06,
      "loss": 0.0819,
      "step": 5600
    },
    {
      "epoch": 4.775993237531699,
      "grad_norm": 4.512447834014893,
      "learning_rate": 9.858458537136208e-07,
      "loss": 0.0796,
      "step": 5650
    },
    {
      "epoch": 4.818258664412511,
      "grad_norm": 15.474825859069824,
      "learning_rate": 7.998372020695414e-07,
      "loss": 0.0858,
      "step": 5700
    },
    {
      "epoch": 4.860524091293322,
      "grad_norm": 14.605815887451172,
      "learning_rate": 6.13828550425462e-07,
      "loss": 0.0794,
      "step": 5750
    },
    {
      "epoch": 4.902789518174133,
      "grad_norm": 3.360483169555664,
      "learning_rate": 4.278198987813826e-07,
      "loss": 0.0878,
      "step": 5800
    },
    {
      "epoch": 4.945054945054945,
      "grad_norm": 9.393097877502441,
      "learning_rate": 2.418112471373032e-07,
      "loss": 0.0858,
      "step": 5850
    },
    {
      "epoch": 4.987320371935756,
      "grad_norm": 7.840747356414795,
      "learning_rate": 5.580259549322381e-08,
      "loss": 0.0875,
      "step": 5900
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8640304504123494,
      "eval_f1": 0.863670482477173,
      "eval_loss": 0.5357721447944641,
      "eval_runtime": 34.1073,
      "eval_samples_per_second": 277.301,
      "eval_steps_per_second": 34.685,
      "step": 5915
    }
  ],
  "logging_steps": 50,
  "max_steps": 5915,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6249017064198144.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": {
    "learning_rate": 2.200482348949459e-05,
    "num_train_epochs": 5,
    "per_device_train_batch_size": 32,
    "weight_decay": 0.07755998563680813
  }
}
